gcloud compute instances describe INSTANCE_NAME \
    --project=YOUR_PROJECT_ID \
    --zone=YOUR_INSTANCE_ZONE \
    --format="value(instanceGroup)"

gcloud compute instance-groups describe INSTANCE_GROUP_NAME \
    --project=YOUR_PROJECT_ID \
    --zone=YOUR_INSTANCE_GROUP_ZONE \
    --format="value(backends)"

# Step 1: Find the forwarding rule associated with the backend service
BACKEND_SERVICE_NAME="YOUR_BACKEND_SERVICE_NAME"
gcloud compute backend-services describe "${BACKEND_SERVICE_NAME}" \
    --project=YOUR_PROJECT_ID \
    --global \
    --format="value(selfLink)" | \
    xargs gcloud compute forwarding-rules list \
    --project=YOUR_PROJECT_ID \
    --global \
    --format="table(NAME)"

# Step 2: Get the IP address of the forwarding rule used
FORWARDING_RULE_NAME="YOUR_FORWARDING_RULE_NAME"
gcloud compute forwarding-rules describe "${FORWARDING_RULE_NAME}" \
    --project=YOUR_PROJECT_ID \
    --global \
    --format="value(IPAddress)"




foreach ($projectID in $projects) {
    Write-Host "Project: $projectID`n"

    # Get a list of Cloud SQL instances
    $instances = gcloud sql instances list --project $projectID --format="value(NAME)" | ForEach-Object { $_.Trim() }

    # Iterate over each instance
    foreach ($instance in $instances) {
        # Get the labels for the instance
        $labels = gcloud sql instances describe $instance --project $projectID --format="value(labels)"

        # Check if the label 'terraformed=true' is not present
        if (-not $labels -or $labels -notlike "*terraformed=true*") {
            Write-Host $instance
        }
    }

    Write-Host
}





from google.cloud import sql_v1beta4
from google.auth import credentials

PROJECTS = ["project1-id", "project2-id", "project3-id"]

for project_id in PROJECTS:
    print(f"Project: {project_id}\n")

    # Create the Cloud SQL client
    credentials, _ = google.auth.default()
    client = sql_v1beta4.CloudSqlClient(credentials=credentials)

    # Get a list of Cloud SQL instances
    instances = client.list_instances(project=project_id)

    # Iterate over each instance
    for instance in instances:
        instance_name = instance.name
        labels = instance.resource.labels

        # Check if the label 'terraformed=true' is not present
        if not labels or labels.get("terraformed") != "true":
            print(instance_name)

    print()



import subprocess

PROJECTS = ["project1-id", "project2-id", "project3-id"]

for project_id in PROJECTS:
    print(f"Project: {project_id}\n")

    # Get a list of Cloud SQL instances
    instances_output = subprocess.check_output(
        f"gcloud sql instances list --project {project_id} --format='value(NAME)'",
        shell=True,
    )
    instances = instances_output.decode("utf-8").strip().split("\n")

    # Iterate over each instance
    for instance in instances:
        # Get the labels for the instance
        labels_output = subprocess.check_output(
            f"gcloud sql instances describe {instance} --project {project_id} --format='value(labels)'",
            shell=True,
        )
        labels = labels_output.decode("utf-8").strip()

        # Check if the label 'terraformed=true' is not present
        if "terraformed=true" not in labels:
            print(instance)

    print()







#!/bin/bash

CONNECTION_NAME="YOUR_CONNECTION_NAME"

# Get a list of connection IDs matching the specified name
connection_ids=$(airflow connections list | awk -v name="$CONNECTION_NAME" '$2 == name {print $1}')

# Loop through the connection IDs and delete each connection
for conn_id in $connection_ids; do
    airflow connections --delete --conn_id "$conn_id"
done


import json
from airflow.hooks.base_hook import BaseHook

connections = BaseHook.get_connections()

json_file = '/path/to/connections.json'

connections_data = []
for connection in connections:
    connections_data.append({
        'conn_id': connection.conn_id,
        'conn_type': connection.conn_type,
        'host': connection.host,
        'login': connection.login,
        'password': connection.password,
        'schema': connection.schema,
        'port': connection.port,
        'extra': connection.extra
    })

with open(json_file, 'w') as file:
    json.dump(connections_data, file, indent=4)

print(f"Connections exported to {json_file}")





import json
from airflow import models

connections = models.Connection().find_all()

json_file = '/path/to/connections.json'

connections_data = []
for connection in connections:
    connections_data.append({
        'conn_id': connection.conn_id,
        'conn_type': connection.conn_type,
        'host': connection.host,
        'login': connection.login,
        'password': connection.password,
        'schema': connection.schema,
        'port': connection.port,
        'extra': connection.extra
    })

with open(json_file, 'w') as file:
    json.dump(connections_data, file, indent=4)

print(f"Connections exported to {json_file}")



#!/bin/bash

PROJECTS=("project1-id" "project2-id" "project3-id")

# Iterate over each project
for PROJECT_ID in "${PROJECTS[@]}"; do
  echo "Project: ${PROJECT_ID}"

  # Get a list of Cloud SQL instances
  INSTANCES=$(gcloud sql instances list --project "${PROJECT_ID}" --format "value(NAME)")

  # Iterate over each instance
  for INSTANCE in ${INSTANCES}; do
    # Get the labels for the instance
    LABELS=$(gcloud sql instances describe "${INSTANCE}" --project "${PROJECT_ID}" --format "value(labels)")

    # Check if the label 'terraformed=true' is not present
    if [[ ! "${LABELS}" =~ terraformed=true ]]; then
      echo "${INSTANCE}"
    fi
  done

  echo
done

